{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting video to image array...\n",
      "Image array successfully created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageOps\n",
    "from moviepy.editor import VideoFileClip, ImageSequenceClip\n",
    "import numpy as np\n",
    "\n",
    "# Function to convert video to images\n",
    "def video_to_images(video_path, output_dir, fps):\n",
    "    clip = VideoFileClip(video_path)\n",
    "    duration = clip.duration\n",
    "    frame_rate = clip.fps\n",
    "    frame_times = np.arange(0, duration, 1.0 / fps)\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    images = []\n",
    "    font_size = int(clip.size[1] * 0.05)    # 5% the height of the video\n",
    "    font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
    "    position = (10, 10)\n",
    "\n",
    "    for timestamp in frame_times:\n",
    "        img = clip.get_frame(timestamp)\n",
    "        img_pil = Image.fromarray(img)\n",
    "        timestamp_text = f\"Time: {timestamp:.2f}s\"\n",
    "\n",
    "        # masking technique to draw inverted text on the image\n",
    "        text_mask = Image.new(\"L\", img_pil.size, 0)\n",
    "        draw_mask = ImageDraw.Draw(text_mask)\n",
    "        draw_mask.text(position, timestamp_text, fill=255, font=font)\n",
    "        inverted_image = ImageOps.invert(img_pil)                           # invert the colors in the region of the text\n",
    "        final_image = Image.composite(inverted_image, img_pil, text_mask)   # combine the original image with the inverted region using the text mask\n",
    "\n",
    "        # save the resultant image to path (may or may not replace with in-memory-image-data-management)\n",
    "        image_path = os.path.join(output_dir, f\"f_{int(timestamp * fps):04d}.jpg\")\n",
    "        final_image.save(image_path, \"JPEG\")\n",
    "        images.append(image_path)\n",
    "\n",
    "    return images, frame_rate, fps\n",
    "\n",
    "input_video_path = \"input.mp4\"\n",
    "VideoFileClip(\"30_second_animation_assignment.mp4\").write_videofile(input_video_path, codec='libx264', logger=None)\n",
    "output_dir = \"output\"\n",
    "print(\"Converting video to image array...\")\n",
    "images, original_fps, reduced_fps = video_to_images(input_video_path, output_dir, fps=2)\n",
    "clip = ImageSequenceClip(images,fps=1)\n",
    "print(\"Image array successfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"output.mp4\" controls  width=\"500\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Video\n",
    "\n",
    "# sanity check: ensure the image array has been edited correctly\n",
    "output_video_path = \"output.mp4\"\n",
    "clip.write_videofile(output_video_path, codec='libx264', logger=None)\n",
    "display(Video(output_video_path, width=500))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
