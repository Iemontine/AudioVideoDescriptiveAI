{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 22 frames...\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from IPython.display import display, Image, Audio\n",
    "import cv2\n",
    "import base64\n",
    "import time\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "base64Frames = []\n",
    "video = cv2.VideoCapture(\"./videos/output.mp4\")\n",
    "while video.isOpened():\n",
    "    success, frame = video.read()\n",
    "    if not success:\n",
    "        break\n",
    "    _, buffer = cv2.imencode(\".jpg\", frame)\n",
    "    base64Frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n",
    "\n",
    "# check loading of video\n",
    "display_handle = display(None, display_id=True)\n",
    "print(f\"Length of image array: {len(base64Frames)}\")\n",
    "for img in base64Frames:\n",
    "    display_handle.update(Image(data=base64.b64decode(img.encode(\"utf-8\")), width=600))\n",
    "    time.sleep(1/48)\n",
    "reducedFrames = base64Frames[0::4]\n",
    "print(f\"Processing {len(reducedFrames)} frames...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion tokens used: 586\n",
      "Prompt tokens used: 81106\n",
      "Total tokens used: 81692\n",
      "```srt\n",
      "1\n",
      "00:00:00,000 --> 00:00:01,333\n",
      "A girl sits on a bed, focused on her laptop. \n",
      "\n",
      "2\n",
      "00:00:01,333 --> 00:00:02,666\n",
      "Raindrops begin to pour against the window. \n",
      "\n",
      "3\n",
      "00:00:02,666 --> 00:00:04,000\n",
      "Suddenly, a loud explosion is heard. \n",
      "\n",
      "4\n",
      "00:00:04,000 --> 00:00:05,333\n",
      "She turns around, startled by the noise. \n",
      "\n",
      "5\n",
      "00:00:05,333 --> 00:00:06,666\n",
      "The rain continues to fall as thunder rumbles. \n",
      "\n",
      "6\n",
      "00:00:06,666 --> 00:00:09,000\n",
      "The girl stands up, walking towards the window. \n",
      "\n",
      "7\n",
      "00:00:09,000 --> 00:00:10,866\n",
      "Outside, the rain pours heavily onto the plants. \n",
      "\n",
      "8\n",
      "00:00:10,866 --> 00:00:12,000\n",
      "She seems captivated by the view. \n",
      "\n",
      "9\n",
      "00:00:12,000 --> 00:00:13,333\n",
      "A close-up shows her smiling gently. \n",
      "\n",
      "10\n",
      "00:00:13,333 --> 00:00:14,666\n",
      "She appears to enjoy being in the rain. \n",
      "\n",
      "11\n",
      "00:00:14,666 --> 00:00:16,000\n",
      "Next, she's shown putting on a raincoat. \n",
      "\n",
      "12\n",
      "00:00:16,000 --> 00:00:17,333\n",
      "The sounds of the rain persist. \n",
      "\n",
      "13\n",
      "00:00:17,333 --> 00:00:18,666\n",
      "She steps into bright yellow rain boots. \n",
      "\n",
      "14\n",
      "00:00:18,666 --> 00:00:20,000\n",
      "The camera focuses on her feet planting on the floor. \n",
      "\n",
      "15\n",
      "00:00:20,000 --> 00:00:21,333\n",
      "She walks confidently outside. \n",
      "\n",
      "16\n",
      "00:00:21,333 --> 00:00:22,666\n",
      "The view shifts to show her leaving the house. \n",
      "\n",
      "17\n",
      "00:00:22,666 --> 00:00:24,000\n",
      "Rain continues to soak everything around. \n",
      "\n",
      "18\n",
      "00:00:24,000 --> 00:00:25,333\n",
      "As she steps on the porch, she pauses. \n",
      "\n",
      "19\n",
      "00:00:25,333 --> 00:00:26,666\n",
      "She looks thrilled and ready for adventure. \n",
      "\n",
      "20\n",
      "00:00:26,666 --> 00:00:28,000\n",
      "The screen fades to black with a sound of drizzle. \n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff\n",
    "\n",
    "prompt = \"\"\"\n",
    "These are frames from a video that I want to upload. \n",
    "Can you make a recap of what happens in the video, taking note of major changes of events in the video. \n",
    "Be detailed as to create an audio descriptive aid. Speak naturally and in a way that would be helpful to someone who is visually impaired.\n",
    "Minimize the number of seperate Time events you use, which means grouping together events as much as possible.\n",
    "Attempt to interpret the events in the video where possible, but do not provide or use any information that is not explicitly present in the video.\n",
    "The current sound effect detected is provided at the top left of each frame, use this to help describe events but do not mention the provision of this context.\n",
    "The current timestamp is also provided in the top left of each frame.\n",
    "Do not provide an overall summary.\n",
    "Your output should be only the content of a .srt file.\n",
    "For each caption in the srt, it is very important that it is able to be spoken within the timestamps you provide such that it can be read out loud within the duration of the timestamp.\n",
    "It is of upmost importance that the captions are accurate, the timings do not overlap, and that the captions are within the duration of the video.\n",
    "\"\"\"\n",
    "PROMPT_MESSAGES = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            prompt,\n",
    "            *map(lambda x: {\"image\": x, \"resize\": 300}, reducedFrames),\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "params = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"messages\": PROMPT_MESSAGES,\n",
    "}\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def generate_with_backoff(**kwargs):\n",
    "    result = client.chat.completions.create(**kwargs)\n",
    "    print(f\"Completion tokens used: {result.usage.completion_tokens}\")\n",
    "    print(f\"Prompt tokens used: {result.usage.prompt_tokens}\")\n",
    "    print(f\"Total tokens used: {result.usage.total_tokens}\")\n",
    "    return result\n",
    "\n",
    "result = generate_with_backoff(**params)\n",
    "\n",
    "print(result.choices[0].message.content)\n",
    "with open('output_subtitles.srt', 'w') as f:\n",
    "    f.write(result.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
